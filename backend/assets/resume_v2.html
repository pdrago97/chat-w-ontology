<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pedro Reichow - Resume</title>
    <style>
        :root {
            --primary: #1a2332;
            --accent: #1e6fa0;
            --text: #2d2d2d;
            --text-light: #555555;
            --bg: #ffffff;
            --border: #d0d0d0;
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: 'Georgia', serif;
            color: var(--text);
            line-height: 1.45;
            background: #f5f5f5;
            padding: 2rem;
        }

        .resume-container {
            max-width: 900px;
            margin: 0 auto;
            background: var(--bg);
            padding: 2.5rem 3rem;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        header {
            text-align: center;
            margin-bottom: 1.5rem;
            border-bottom: 2px solid var(--primary);
            padding-bottom: 1.2rem;
        }

        h1 {
            font-family: 'Arial', sans-serif;
            font-size: 2rem;
            text-transform: uppercase;
            letter-spacing: 2px;
            color: var(--primary);
            margin-bottom: 0.4rem;
        }

        .contact-info {
            font-family: 'Arial', sans-serif;
            font-size: 0.88rem;
            color: var(--text);
        }

        .contact-info a {
            color: var(--text);
            text-decoration: none;
        }

        section {
            margin-bottom: 1.5rem;
        }

        h2 {
            font-family: 'Arial', sans-serif;
            font-size: 1.05rem;
            text-transform: uppercase;
            color: var(--accent);
            border-bottom: 1px solid var(--border);
            padding-bottom: 0.25rem;
            margin-bottom: 0.8rem;
            font-weight: 700;
            letter-spacing: 0.5px;
        }

        .job {
            margin-bottom: 1.3rem;
        }

        .job-header {
            display: flex;
            justify-content: space-between;
            align-items: baseline;
            margin-bottom: 0.2rem;
        }

        .company {
            font-weight: 700;
            font-size: 1rem;
            color: var(--primary);
        }

        .role {
            font-style: italic;
            font-weight: 600;
            color: var(--text);
            font-size: 0.95rem;
        }

        .location {
            font-size: 0.85rem;
            color: var(--text-light);
            margin-left: 0.5rem;
        }

        .date {
            font-family: 'Arial', sans-serif;
            font-size: 0.85rem;
            color: var(--text-light);
            font-weight: 600;
            white-space: nowrap;
        }

        .job-details ul {
            list-style-type: disc;
            padding-left: 1.2rem;
            margin-top: 0.4rem;
        }

        .job-details li {
            margin-bottom: 0.25rem;
            font-size: 0.92rem;
        }

        .summary-text {
            font-size: 0.93rem;
            text-align: justify;
            line-height: 1.5;
        }

        /* Skills - compact inline */
        .skills-inline {
            font-size: 0.9rem;
            line-height: 1.6;
        }

        .skills-inline .skill-line {
            margin-bottom: 0.3rem;
        }

        .skills-inline .skill-label {
            font-weight: 700;
            color: var(--primary);
        }

        /* Education compact */
        .edu-item {
            display: flex;
            justify-content: space-between;
            margin-bottom: 0.3rem;
            font-size: 0.92rem;
        }

        .edu-item .edu-school {
            font-weight: 600;
        }

        @media print {
            body {
                background: white;
                padding: 0;
            }

            .resume-container {
                box-shadow: none;
                padding: 0;
                max-width: 100%;
            }

            .no-print {
                display: none !important;
            }
        }

        .print-btn {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            background: var(--accent);
            color: white;
            border: none;
            padding: 0.8rem 1.5rem;
            border-radius: 50px;
            font-weight: 600;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
            z-index: 100;
            font-size: 0.9rem;
        }
    </style>
</head>

<body>
    <button class="print-btn no-print" onclick="window.print()">Save as PDF</button>

    <div class="resume-container">
        <header>
            <h1>Pedro Reichow</h1>
            <div class="contact-info">
                pedroreichow3@gmail.com &bull; linkedin.com/in/pedroreichow &bull; pedroreichow.com.br
            </div>
        </header>

        <!-- SUMMARY -->
        <section>
            <h2>Summary</h2>
            <div class="summary-text">
                AI &amp; Data Engineering leader with 8+ years of experience across fintech, healthcare, and enterprise
                SaaS.
                Currently building production AI agent systems at Santodigital (Google Cloud Partner) &mdash; shipping
                8+ agent
                deployments with full-stack interfaces, document intelligence pipelines, and dynamic enterprise
                federation.
                Built data pipelines processing 500GB+ daily at QI Tech, designed RDF/OWL ontologies and knowledge
                graphs on Anzo Analytics at Capgemini for fraud detection, and led AI observability across 12+ models
                at CVS Health under HIPAA/FedRAMP.
                Co-founded two AI ventures: MoveUp AI (multi-agent orchestration for 15+ enterprise teams) and
                Trinnix AI Lab (computer vision &amp; knowledge graphs for precision agriculture).
                Hands-on from PySpark/Spark Streaming at scale to deploying LLM agents with Google ADK, LangGraph,
                vector databases, and MCP orchestration.
            </div>
        </section>

        <!-- ENTREPRENEURIAL EXPERIENCE -->
        <section>
            <h2>Entrepreneurial Experience</h2>

            <!-- MoveUp AI -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">MoveUp AI</span>
                        <span class="location">San Francisco, CA (Remote)</span>
                    </div>
                    <span class="date">Jan 2025 &ndash; Jul 2025</span>
                </div>
                <div class="role">Founding Engineer &amp; Technical Co-founder</div>
                <div class="job-details">
                    <ul>
                        <li>Co-founded AI workforce intelligence platform serving 15+ enterprise teams; designed the
                            entire
                            technical architecture from zero to production deployment.</li>
                        <li>Built graph-based multi-agent orchestration system with specialized agents (research,
                            analysis,
                            action) coordinating via shared memory pools and tool-use protocols using LangGraph and
                            Agno.</li>
                        <li>Architected knowledge graph infrastructure with FalkorDB and Neo4j, integrating Supabase
                            vector
                            stores and Zep persistent memory for long-term contextual agent reasoning across 50K+
                            documents.</li>
                        <li>Designed and deployed MCP (Model Context Protocol) servers in TypeScript enabling
                            agent-to-agent
                            communication across Slack, CRM, and internal tools with sub-second latency.</li>
                        <li>Built end-to-end autonomous workflows with N8N orchestration: agents that research, draft,
                            review,
                            and deliver reports without manual intervention, reducing analyst workload by ~60%.</li>
                    </ul>
                </div>
            </div>

            <!-- Trinnix AI Lab -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">Trinnix AI Lab</span>
                    </div>
                    <span class="date">Feb 2024 &ndash; Nov 2024</span>
                </div>
                <div class="role">Co-founder &amp; Lead AI Engineer</div>
                <div class="job-details">
                    <ul>
                        <li>Co-founded AI consulting lab focused on computer vision, LLM integration, and knowledge
                            graph
                            solutions for agricultural technology and precision farming clients.</li>
                        <li>Built and deployed agricultural monitoring systems using YOLOv8 and Roboflow, achieving
                            &gt;95%
                            accuracy in plant disease detection and livestock behavioral analysis across 3 crop/breed
                            types.</li>
                        <li>Architected ontological knowledge graphs with Neo4j for agricultural data modeling and
                            business
                            intelligence, enabling semantic queries across geospatial, environmental, and production
                            datasets.</li>
                        <li>Integrated multiple commercial LLMs (GPT-4o, Claude 3.5, Gemini 1.5) with advanced prompt
                            engineering chains for automated field reporting, anomaly alerting, and agronomic insights.
                        </li>
                        <li>Built scalable full-stack platforms with TypeScript, tRPC, and Node.js serving geospatial
                            analysis
                            dashboards with real-time sensor data overlays and satellite imagery integration.</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- PROFESSIONAL EXPERIENCE -->
        <section>
            <h2>Professional Experience</h2>

            <!-- Santodigital -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">Santodigital</span>
                        <span class="location">Google Cloud Premier Partner, Brazil</span>
                    </div>
                    <span class="date">Jan 2024 &ndash; Present</span>
                </div>
                <div class="role">Cloud AI Solutions Architect &amp; Agent Developer</div>
                <div class="job-details">
                    <ul>
                        <li>Designed and shipped 8+ production AI agent systems for enterprise clients using Google ADK,
                            building full-stack interfaces (React + FastAPI) that bridge LLM capabilities with business
                            workflows â€” document analysis, contract review, compliance automation, and customer service
                            bots.</li>
                        <li>Built end-to-end document intelligence pipelines: PDF/image ingestion, metadata extraction
                            with
                            structured output parsing, semantic chunking, and vector indexing on Vertex AI + BigQuery,
                            processing 100K+ documents across client deployments.</li>
                        <li>Architected dynamic federation integrations connecting AI agents to client ERP, CRM, and
                            internal systems via REST/gRPC adapters, enabling agents to query live data sources and
                            execute
                            actions across heterogeneous enterprise environments.</li>
                        <li>Designed production RAG pipelines with offline evaluation suites (RAGAS framework) measuring
                            retrieval precision, faithfulness, and answer relevance; implemented agentic reinforcement
                            loops
                            where observability telemetry feeds prompt versioning, reducing hallucination rates by 35%.
                        </li>
                        <li>Built multi-agent orchestration patterns: autonomous compliance monitoring with alert
                            escalation,
                            contract clause extraction agents with human-in-the-loop review gates, and auto-service
                            agents
                            with Zendesk handoff for critical customer interactions.</li>
                        <li>Managed training data operations for domain-specific fine-tuning: annotation workflows, data
                            quality validation pipelines, and versioned dataset management on GCS with DVC, supporting
                            model iteration cycles across 5+ client verticals.</li>
                    </ul>
                </div>
            </div>

            <!-- CVS Health -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">CVS Health</span>
                    </div>
                    <span class="date">Aug 2024 &ndash; Dec 2025</span>
                </div>
                <div class="role">Senior Data &amp; AI Engineer | AI Observability Lead</div>
                <div class="job-details">
                    <ul>
                        <li>Defined and implemented SLOs for AI pipeline latency (p50/p95/p99) and cost-per-token
                            monitoring
                            using Datadog and Grafana across 12+ healthcare AI models in HIPAA/FedRAMP-compliant
                            environments.</li>
                        <li>Built real-time observability dashboards tracking faithfulness, relevance, and groundedness
                            metrics
                            for LLM outputs, enabling prompt version A/B testing that improved accuracy by 22%.</li>
                        <li>Led a team of 4 engineers developing enterprise agentic applications with predictive
                            analysis,
                            multi-step reasoning pipelines, and autonomous workflow orchestration using Python and
                            TypeScript.</li>
                        <li>Designed data ingestion pipelines processing clinical and pharmacy datasets (200GB+ daily)
                            using
                            Apache Spark and Airflow, feeding ML models for patient outcome prediction.</li>
                    </ul>
                </div>
            </div>

            <!-- Capgemini -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">Capgemini Brasil</span>
                    </div>
                    <span class="date">Jan 2022 &ndash; Dec 2023</span>
                </div>
                <div class="role">Senior Solutions Consultant &amp; Knowledge Engineer</div>
                <div class="job-details">
                    <ul>
                        <li>Architected enterprise knowledge graph platform using Anzo Analytics with RDF/OWL
                            ontologies for fraud detection and risk scoring in the financial sector, processing 10M+
                            entity relationships across distributed semantic stores.</li>
                        <li>Designed domain ontologies with Prot&eacute;g&eacute; (SKOS, RDF, OWL) and built SPARQL
                            query interfaces on Anzo Analytics, enabling semantic search and complex business
                            intelligence queries across heterogeneous financial datasets.</li>
                        <li>Built Python API middleware with FastAPI wrapping SPARQL endpoints, serving as the
                            abstraction layer between the Anzo graph store, relational databases, and front-end
                            applications; handled 2K+ requests/sec in production.</li>
                        <li>Led data modeling initiatives across a 50+ engineer team: defined ontology standards, entity
                            resolution pipelines, and data quality frameworks for financial transaction datasets.</li>
                        <li>Implemented ETL pipelines with PySpark and Airflow for daily ingestion of 100GB+ financial
                            records into the knowledge graph, with automated anomaly detection and alerting.</li>
                    </ul>
                </div>
            </div>

            <!-- Simulated Reality -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">Simulated Reality</span>
                    </div>
                    <span class="date">Jan 2021 &ndash; Dec 2021</span>
                </div>
                <div class="role">Full Stack Engineer | VR, Real-Time &amp; 3D Systems</div>
                <div class="job-details">
                    <ul>
                        <li>Built scalable backend for VR training and healthcare wellness applications using Node.js
                            and
                            React, serving 10K+ concurrent sessions with WebSocket real-time communication and spatial
                            coordinate synchronization for multi-user 3D environments.</li>
                        <li>Designed event-driven architecture with RabbitMQ and pub/sub patterns for asynchronous
                            processing
                            of large 3D assets (volumetric video, Unity/Unreal Engine builds, geospatial scene data)
                            totaling 2TB+ weekly throughput across distributed CDN nodes.</li>
                        <li>Developed user behavior analytics pipelines capturing spatial interaction data (gaze
                            tracking,
                            hand position, movement patterns), feeding TensorFlow models for adaptive training
                            experiences
                            and personalized wellness program recommendations.</li>
                        <li>Engineered blockchain-based asset provenance system for tracking VR content licensing and
                            distribution across partner networks, ensuring IP compliance for medical training modules.
                        </li>
                    </ul>
                </div>
            </div>

            <!-- QI Tech -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">QI Tech</span>
                        <span class="location">Fintech</span>
                    </div>
                    <span class="date">Jan 2019 &ndash; Dec 2020</span>
                </div>
                <div class="role">Senior Data Engineer</div>
                <div class="job-details">
                    <ul>
                        <li>Processed 500GB+ daily financial transactions using PySpark (Spark SQL, Spark Streaming) on
                            GCP
                            Dataproc clusters, achieving 40% latency reduction through partition optimization and
                            predicate
                            pushdown tuning.</li>
                        <li>Architected Delta Lake on GCS with ACID transaction guarantees for regulatory audit
                            compliance;
                            designed data versioning and time-travel capabilities enabling ML experiment
                            reproducibility.</li>
                        <li>Built end-to-end ETL/ELT pipelines with Apache Airflow (100+ DAGs) orchestrating data flows
                            from
                            20+ sources into BigQuery data warehouse and Spark-based feature stores.</li>
                        <li>Designed star/snowflake schema data models for the analytics warehouse, supporting real-time
                            dashboards and batch reporting for risk, credit scoring, and regulatory teams.</li>
                        <li>Optimized gRPC microservice communication layer between data services, reducing
                            inter-service
                            latency by 55% and cloud compute costs by 30% through resource right-sizing.</li>
                    </ul>
                </div>
            </div>

            <!-- PecSmart -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">PecSmart</span>
                        <span class="location">IoT &amp; AgTech</span>
                    </div>
                    <span class="date">Nov 2017 &ndash; Dec 2018</span>
                </div>
                <div class="role">Backend Developer &amp; Data Engineer</div>
                <div class="job-details">
                    <ul>
                        <li>Built real-time IoT data pipelines ingesting sensor streams from 500+ Raspberry Pi devices
                            monitoring livestock behavior, processing 50K+ events/hour with Python and Redis Streams.
                        </li>
                        <li>Developed computer vision models (OpenCV, early YOLO) for automated animal health
                            assessment,
                            achieving &gt;95% accuracy in disease detection across 3 cattle breeds.</li>
                        <li>Designed PostgreSQL time-series data models and batch analytics pipelines feeding predictive
                            models for feed optimization, reducing operational costs by 20% for partner farms.</li>
                    </ul>
                </div>
            </div>

            <!-- Fontes Promotora -->
            <div class="job">
                <div class="job-header">
                    <div>
                        <span class="company">Fontes Promotora</span>
                        <span class="location">Fintech</span>
                    </div>
                    <span class="date">Jan 2017 &ndash; Oct 2017</span>
                </div>
                <div class="role">Backend Developer</div>
                <div class="job-details">
                    <ul>
                        <li>Built RESTful APIs using Django REST and Flask, creating a middleware abstraction layer
                            serving
                            front-end applications from multiple database backends (PostgreSQL, MongoDB).</li>
                        <li>Developed data collection pipelines using Scrapy for automated financial data extraction
                            from
                            30+ sources, feeding analytics dashboards and credit assessment models.</li>
                        <li>Delivered full-stack solutions with React frontend deployed on AWS (EC2, S3, RDS) with
                            Docker
                            containerization and CI/CD via GitHub Actions.</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- TECHNICAL EXPERTISE -->
        <section>
            <h2>Technical Expertise</h2>
            <div class="skills-inline">
                <div class="skill-line">
                    <span class="skill-label">Languages &amp; Frameworks:</span>
                    Python, TypeScript, JavaScript, SQL, Java (reading proficiency), Scala (reading proficiency) |
                    FastAPI, Django, Flask, React, Node.js, GraphQL, gRPC
                </div>
                <div class="skill-line">
                    <span class="skill-label">AI &amp; ML:</span>
                    LangGraph, LangChain, CrewAI, Agno, Google ADK | RAG Pipelines, Multi-Agent Orchestration,
                    MCP Servers, Prompt Engineering | TensorFlow, PyTorch, OpenCV, YOLOv8 |
                    LLMs (Claude, GPT-4, Gemini, Llama, Qwen)
                </div>
                <div class="skill-line">
                    <span class="skill-label">Data Engineering:</span>
                    Apache Spark (PySpark, Spark SQL, Streaming), Apache Airflow, Apache Flink, Delta Lake,
                    Hadoop (HDFS, MapReduce) | ETL/ELT, Data Modeling (Star/Snowflake), Data Quality Frameworks,
                    Stream Processing
                </div>
                <div class="skill-line">
                    <span class="skill-label">Knowledge &amp; Search:</span>
                    Neo4j, FalkorDB, RDF/OWL/SKOS Ontologies, SPARQL, Prot&eacute;g&eacute; |
                    Vector Databases (Supabase, Pinecone, Chroma), Semantic Search, Entity Resolution
                </div>
                <div class="skill-line">
                    <span class="skill-label">Cloud &amp; Infrastructure:</span>
                    GCP (BigQuery, Dataproc, Composer, Vertex AI, GCS), AWS (S3, Redshift, Glue, Lambda, EMR),
                    Azure | Docker, Kubernetes, Terraform | CI/CD, Datadog, Grafana
                </div>
                <div class="skill-line">
                    <span class="skill-label">Specialized Systems:</span>
                    Real-Time 3D/VR (Unity, Unreal Engine, WebSocket), Geospatial Data Processing,
                    IoT Pipelines (Raspberry Pi, Redis Streams), Blockchain Asset Provenance,
                    Distributed CDN Architecture
                </div>
            </div>
        </section>

        <!-- EDUCATION -->
        <section>
            <h2>Education</h2>
            <div class="edu-item">
                <div><span class="edu-school">Estacio University</span> &mdash; B.Sc. Systems Analysis &amp; Development
                </div>
                <span class="date">2020 - 2023</span>
            </div>
            <div class="edu-item">
                <div><span class="edu-school">Federal University of Santa Catarina (UFSC)</span> &mdash; B.Sc.
                    Electrical Engineering</div>
                <span class="date">2017 - 2020</span>
            </div>
            <div class="edu-item">
                <div><span class="edu-school">Federal Institute of Santa Catarina (IFSC)</span> &mdash; Technical
                    Diploma, Electrotechnics</div>
                <span class="date">2014 - 2017</span>
            </div>
        </section>
    </div>
</body>

</html>